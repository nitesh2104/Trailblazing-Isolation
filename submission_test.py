#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebook.ipynb
import traceback

from board_viz import *
from isolation import game_as_text
from test_players import *


# Credits if any
# 1)
# 2)
# 3)

class OpenMoveEvalFn:
    def score(self, game, maximizing_player=None):
        """Score the current game state
        Evaluation function that outputs a score equal to how many
        moves are open for AI player on the board minus how many moves
        are open for Opponent's player on the board.
        # Currently Im assuming that we are calculating the score of just 1 state
        # So some other function will generate all possible moves and forecast them
        # Then for each forecast move, call this method to get the score and add all score for a given depth
        # Once all the nodes in a given depth are scored, store it in a dictionary to use in case we run out of time
        # The goal is to calculate as many scores as possible per move
        # Alpha-beta pruning is one of the ways to reduce the score computations
        # Custom evaluation function will also reduce the computatation factor
        # So for now, we are doing Breadth First Search and with AB Pruning, we can make it more efficient
        # Now we still need the Agent to be as fast as possible in computing the scores of as many valid nodes
        # One way could be using C code? Will have to research and see
        # Try to make space-time complexity more efficient

        Note:
            If you think of better evaluation function, do it in CustomEvalFn below.

            Args
                game (Board): The board and game state.
                my_player (Player object): This specifies which player you are.

            Returns:
                float: The current state's score. MyMoves-OppMoves.

            """

        # Get the valid moves for active and inactive player
        # active_player = game.get_active_player()
        # print("Current: {}".format(active_player.name))
        active_player = game.get_active_player()
        active_player_moves = game.get_player_moves(active_player)
        inactive_player_moves = game.get_opponent_moves(active_player)

        active_player_moves_len = len(active_player_moves)
        inactive_player_moves_len = len(inactive_player_moves)

        if maximizing_player != game.get_active_player():
            final_score = inactive_player_moves_len - active_player_moves_len
        else:
            final_score = active_player_moves_len - inactive_player_moves_len
        return final_score


class CustomPlayer:
    # TODO: finish this class!
    """Player that chooses a move using your evaluation function
    and a minimax algorithm with alpha-beta pruning.

    You must finish and test this player to make sure it properly
    uses minimax and alpha-beta to return a good move."""

    def __init__(self, search_depth=3, eval_fn=OpenMoveEvalFn(), name="CustomPlayer"):
        """Initializes your player.

        if you find yourself with a superior eval function, update the default
        value of `eval_fn` to `CustomEvalFn()`

        Args:
            search_depth (int): The depth to which your agent will search
            eval_fn (function): Evaluation function used by your agent
        """
        self.eval_fn = eval_fn
        self.search_depth = search_depth
        self.name = name

    def move(self, game, time_left):
        """Called to determine one move by your agent

        Note:
            1. Do NOT change the name of this 'move' function. We are going to call
            this function directly.
            2. Call alphabeta instead of minimax once implemented.
        Args:
            game (Board): The board and game state.
            time_left (function): Used to determine time left before timeout

        Returns:
            tuple: (int,int): Your best move
        """
        if not game.get_player_moves(self):
            return None
        else:
            best_move, utility = minimax(self, game, time_left, depth=self.search_depth)
            return best_move

    def utility(self, game, my_turn):
        """You can handle special cases here (e.g. endgame)"""
        return self.eval_fn.score(game, self)

    def get_name(self):
        return self.name


def minimax(player, game, time_left, depth, my_turn=True, current_depth=0, move=None):
    if current_depth == depth or not game.get_active_moves():
        return OpenMoveEvalFn().score(game, player)

    # Get Current Moves of this game state
    current_moves = game.get_active_moves()

    if my_turn:
        # First obtain the score for the current depth - in case if there is any timeout, we can return the value
        curr_depth_score_min = float("-inf")
        for moves in current_moves:
            new_board, is_over, winner = game.forecast_move(moves)
            this_board_score = OpenMoveEvalFn().score(new_board, player)
            if this_board_score > curr_depth_score_min:
                curr_depth_score_min = this_board_score
                final_move = moves
        # Otherwise keep creating the dfs tree if no timeout
        score_list = []
        for move in current_moves:
            new_board, is_over, winner = game.forecast_move(move)
            ret_val = minimax(player, new_board, time_left, depth, False, current_depth + 1, move)
            if type(ret_val) != int:
                ret_val = ret_val[1]
            score_list.append((move, ret_val))
            move, final_score = sorted(score_list, key=lambda x: x[1], reverse=True)[0]

    else:
        # For this depth level, get the min score - in case we run out of time
        curr_depth_score = float("+inf")
        for moves in current_moves:
            new_board, is_over, winner = game.forecast_move(moves)
            this_board_score = OpenMoveEvalFn().score(new_board, player)
            if this_board_score < curr_depth_score:
                curr_depth_score = this_board_score
                final_move = moves

        # Else go ahead and go to deeper levels
        score_list = []
        for move in current_moves:
            new_board, is_over, winner = game.forecast_move(move)
            ret_val = minimax(player, new_board, time_left, depth, True, current_depth + 1, move)
            if type(ret_val) != int:
                ret_val = ret_val[1]
            score_list.append((move, ret_val))

            move, final_score = sorted(score_list, key=lambda x: x[1], reverse=False)[0]
    # We are returning the move and final score - now if the minimax function needs it, it will strip out the move
    # and will only take the final_score. But if in case, it it for the CustomPlayer() move, then the move will be
    # sent back to the class
    return move, final_score


def alphabeta(player, game, time_left, depth, alpha=float("-inf"), beta=float("inf"), my_turn=True):
    """Implementation of the alphabeta algorithm.

    Args:
        player (CustomPlayer): This is the instantiation of CustomPlayer()
            that represents your agent. It is used to call anything you need
            from the CustomPlayer class (the utility() method, for example,
            or any class variables that belong to CustomPlayer())
        game (Board): A board and game state.
        time_left (function): Used to determine time left before timeout
        depth: Used to track how deep you are in the search tree
        alpha (float): Alpha value for pruning
        beta (float): Beta value for pruning
        my_turn (bool): True if you are computing scores during your turn.

    Returns:
        (tuple, int): best_move, val
    """

    # I dont have much idea on how to code the algorithm yet, however I will have a look at the textbook to get an idea
    # TODO: finish this function!
    raise NotImplementedError


class CustomEvalFn:
    def __init__(self):
        pass

    def score(self, game, my_player=None):
        """Score the current game state.

        Custom evaluation function that acts however you think it should. This
        is not required but highly encouraged if you want to build the best
        AI possible.

        Args:
            game (Board): The board and game state.
            my_player (Player object): This specifies which player you are.

        Returns:
            float: The current state's score, based on your own heuristic.
        """
        # I think the goal here is to compute the score but make it quick?? Have to investigate
        # TODO: finish this function!
        raise NotImplementedError


if __name__ == '__main__':
    winnings = 0
    losses = 0
    errors_not_implemented = 0
    errors_others = 0
    games = 10
    for i in range(0, games):
        print("Playing the game: {} iteration".format(i))
        print("")
        try:
            r = RandomPlayer()
            p = CustomPlayer()
            game = Board(r, p, 7, 7)
            output_b = game.copy()
            winner, move_history, termination = game.play_isolation(time_limit=10000, print_moves=True)
            print("\n", winner, " has won. Reason: ", termination)
            if "CustomPlayer" in winner:
                winnings += 1
            else:
                losses += 1
            # Uncomment to see game
            # print(game_as_text(winner, move_history, termination, output_b))
        except NotImplementedError:
            print('CustomPlayer Test: Not Implemented')
            errors_not_implemented += 1
        except:
            errors_others +=1
            print('CustomPlayer Test: ERROR OCCURRED')
            print(traceback.format_exc())


    print("\n\n\n\n")
    print("Total Games: {}".format(len(range(0, games))))
    print("Winnings: {}".format(winnings))
    print("Losses: {}".format(losses))
    print("Not Implemented Errors: {}".format(errors_not_implemented))
    print("Other Errors: {}".format(errors_others))

    try:
        def time_left():  # For these testing purposes, let's ignore timeouts
            return 10000

        if True:
            player = CustomPlayer()  # using as a dummy player to create a board
            sample_board = Board(player, RandomPlayer())
            # setting up the board as though we've been playing
            board_state = [
                [" ", "X", "X", " ", "X", "X", " "],
                [" ", " ", "X", " ", " ", "X", " "],
                ["X", " ", " ", " ", " ", "Q1", " "],
                [" ", "X", "X", "Q2", "X", " ", " "],
                ["X", " ", "X", " ", " ", " ", " "],
                [" ", " ", "X", " ", "X", " ", " "],
                ["X", " ", "X", " ", " ", " ", " "]
            ]
            sample_board.set_state(board_state, True)

            test_pass = True

            expected_depth_scores = [(1, -2), (2, 1), (3, 4), (4, 3), (5, 5)]
            # expected_depth_scores = [(1, -2), (2, 1), (3, 4)]

            for depth, exp_score in expected_depth_scores:
                move, score = minimax(player, sample_board, time_left, depth=depth, my_turn=True)
                if exp_score != score:
                    print("Expected: Depth: {}, Score: {}".format(depth, exp_score))
                    test_pass = False
                else:
                    print("Minimax passed for depth: ", depth)

        if True or test_pass:
            player = CustomPlayer()
            sample_board = Board(RandomPlayer(), player)
            # setting up the board as though we've been playing
            board_state = [
                [" ", " ", " ", " ", "X", " ", "X"],
                ["X", "X", "X", " ", "X", "Q2", " "],
                [" ", "X", "X", " ", "X", " ", " "],
                ["X", " ", "X", " ", "X", "X", " "],
                ["X", " ", "Q1", " ", "X", " ", "X"],
                [" ", " ", " ", " ", "X", "X", " "],
                ["X", " ", " ", " ", " ", " ", " "]
            ]
            sample_board.set_state(board_state, p1_turn=True)

            test_pass = True

            expected_depth_scores = [(1, -7), (2, -7), (3, -7), (4, -9), (5, -8)]
            # expected_depth_scores = [(1, -7), (2, -7)]

            for depth, exp_score in expected_depth_scores:
                move, score = minimax(player, sample_board, time_left, depth=depth, my_turn=False)
                if exp_score != score:
                    print("Minimax failed for depth: ", depth)
                    test_pass = False
                else:
                    print("Minimax passed for depth: ", depth)

        if test_pass:
            print("Minimax Test: Runs Successfully!")

        else:
            print("Minimax Test: Failed")

    except NotImplementedError:
        print('Minimax Test: Not implemented')
    except:
        print('Minimax Test: ERROR OCCURRED')
        print(traceback.format_exc())
