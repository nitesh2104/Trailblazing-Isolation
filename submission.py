#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebook.ipynb
import traceback

import player_submission_tests as tests
from board_viz import *
from test_players import *


# Credits if any
# 1)
# 2)
# 3)

class OpenMoveEvalFn:
    def score(self, game, active_player=None):
        """Score the current game state
        Evaluation function that outputs a score equal to how many
        moves are open for AI player on the board minus how many moves
        are open for Opponent's player on the board.

        Note:
            If you think of better evaluation function, do it in CustomEvalFn below.

            Args
                game (Board): The board and game state.
                my_player (Player object): This specifies which player you are.

            Returns:
                float: The current state's score. MyMoves-OppMoves.

            """
        # Currently Im assuming that we are calculating the score of just 1 state
        # So some other function will generate all possible moves and forecast them
        # Then for each forecast move, call this method to get the score and add all score for a given depth
        # Once all the nodes in a given depth are scored, store it in a dictionary to use in case we run out of time
        # The goal is to calculate as many scores as possible per move
        # Alpha-beta pruning is one of the ways to reduce the score computations
        # Custom evaluation function will also reduce the computatation factor
        # So for now, we are doing Breadth First Search and with AB Pruning, we can make it more efficient
        # Now we still need the Agent to be as fast as possible in computing the scores of as many valid nodes
        # One way could be using C code? Will have to research and see
        # Try to make space-time complexity more efficient

        # Get the valid moves for active and inactive player
        active_player = game.get_active_player()
        inactive_player = game.get_inactive_player()

        active_player_moves = game.get_player_moves(active_player)
        inactive_player_moves = game.get_opponent_moves(active_player)

        active_player_moves_len = len(active_player_moves)
        inactive_player_moves_len = len(inactive_player_moves)

        if active_player == game.__player_1__:
            opp_player = game.__player_2__
        else:
            opp_player = game.__player_1__

        # Depth 1 states of my_player
        game.get_player_moves(active_player)

        # Print the intersecting moves - delete them from the player 2's move

        return len(game.get_player_moves(active_player)) - len(game.get_opponent_moves(active_player))


class CustomPlayer:
    # TODO: finish this class!
    """Player that chooses a move using your evaluation function
    and a minimax algorithm with alpha-beta pruning.
    You must finish and test this player to make sure it properly
    uses minimax and alpha-beta to return a good move."""

    def __init__(self, search_depth=3, eval_fn=OpenMoveEvalFn()):
        """Initializes your player.

        if you find yourself with a superior eval function, update the default
        value of `eval_fn` to `CustomEvalFn()`

        Args:
            search_depth (int): The depth to which your agent will search
            eval_fn (function): Evaluation function used by your agent
        """
        self.eval_fn = eval_fn
        self.search_depth = search_depth

    def move(self, game, time_left):
        """Called to determine one move by your agent

        Note:
            1. Do NOT change the name of this 'move' function. We are going to call
            this function directly.
            2. Call alphabeta instead of minimax once implemented.
        Args:
            game (Board): The board and game state.
            time_left (function): Used to determine time left before timeout

        Returns:
            tuple: (int,int): Your best move
        """
        best_move, utility = minimax(self, game, time_left, depth=self.search_depth)
        return best_move

    def utility(self, game, my_turn):
        """You can handle special cases here (e.g. endgame)"""
        return self.eval_fn.score(game, self)


###################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE CLASS! ################
###### IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ###########
###################################################################

def minimax(player, game, time_left, depth, my_turn=True):
    """Implementation of the minimax algorithm.

    Args:
        player (CustomPlayer): This is the instantiation of CustomPlayer()
            that represents your agent. It is used to call anything you
            need from the CustomPlayer class (the utility() method, for example,
            or any class variables that belong to CustomPlayer()).
        game (Board): A board and game state.
        time_left (function): Used to determine time left before timeout
        depth: Used to track how deep you are in the search tree
        my_turn (bool): True if you are computing scores during your turn.

    Returns:
        (tuple, int): best_move, val
    """

    # The goal is to return the best move co-ordinates for a given state of the board right now
    # So one thing I can assume here is that we can:
    # 1. Find all valid moves
    # 2. Forecast states of all the valid moves (Right now without AB Pruning)
    # 3. For each state calculate the score using score method above
    # 4. Now we need to use the max scores for the active_player and minimize for inactive_player
    # 5.
    # Use memoization to ensure that we are not calculating the same nodes again and again

    print(game)
    print(time_left)
    print(depth)

    maximizer = True
    minimizer = False

    if maximizer:
        print()
    elif minimizer:
        print()
    # TODO: finish this function!
    raise NotImplementedError
    return best_move, best_val


######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
################ END OF LOCAL TEST CODE SECTION ######################

def alphabeta(player, game, time_left, depth, alpha=float("-inf"), beta=float("inf"), my_turn=True):
    """Implementation of the alphabeta algorithm.

    Args:
        player (CustomPlayer): This is the instantiation of CustomPlayer()
            that represents your agent. It is used to call anything you need
            from the CustomPlayer class (the utility() method, for example,
            or any class variables that belong to CustomPlayer())
        game (Board): A board and game state.
        time_left (function): Used to determine time left before timeout
        depth: Used to track how deep you are in the search tree
        alpha (float): Alpha value for pruning
        beta (float): Beta value for pruning
        my_turn (bool): True if you are computing scores during your turn.

    Returns:
        (tuple, int): best_move, val
    """

    # I dont have much idea on how to code the algorithm yet, however I will have a look at the textbook to get an idea
    # TODO: finish this function!
    raise NotImplementedError
    return best_move, val


######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
# tests.name_of_the_test #you can uncomment this line to run your test
################ END OF LOCAL TEST CODE SECTION ######################

class CustomEvalFn:
    def __init__(self):
        pass

    def score(self, game, my_player=None):
        """Score the current game state.

        Custom evaluation function that acts however you think it should. This
        is not required but highly encouraged if you want to build the best
        AI possible.

        Args:
            game (Board): The board and game state.
            my_player (Player object): This specifies which player you are.

        Returns:
            float: The current state's score, based on your own heuristic.
        """
        # I think the goal here is to compute the score but make it quick?? Have to investigate
        # TODO: finish this function!
        raise NotImplementedError


######################################################################
############ DON'T WRITE ANY CODE OUTSIDE THE CLASS! #################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################

if __name__ == '__main__':

    try:
        sample_board = Board(RandomPlayer(), RandomPlayer())
        # setting up the board as though we've been playing
        board_state = [
            ["Q1", " ", " ", " ", " ", " ", " "],
            [" ", " ", " ", " ", " ", " ", " "],
            [" ", " ", " ", " ", " ", " ", " "],
            [" ", " ", " ", "Q2", " ", " ", " "],
            [" ", " ", " ", " ", " ", " ", " "],
            [" ", " ", " ", " ", " ", " ", " "],
            [" ", " ", " ", " ", " ", " ", " "]
        ]
        sample_board.set_state(board_state, True)
        # test = sample_board.get_legal_moves()
        h = OpenMoveEvalFn()
        print('OpenMoveEvalFn Test: This board has a score of %s.' % (
            h.score(sample_board, sample_board.get_active_player())))
    except NotImplementedError:
        print('OpenMoveEvalFn Test: Not implemented')
    except:
        print('OpenMoveEvalFn Test: ERROR OCCURRED')
        print(traceback.format_exc())

    print()
